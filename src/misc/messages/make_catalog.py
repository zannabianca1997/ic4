#!/bin/env python3
"""
    This is a small script that convert a string catalog file to a
    catalog header that can be imported in the program
"""

from dataclasses import dataclass
from datetime import datetime
from enum import Enum, auto
from pathlib import PurePath
from sys import stdin, stdout
from typing import Dict, List, TextIO
from string import ascii_letters, digits, whitespace
from argparse import ArgumentParser, FileType

IDENTIFIER_CHARS = list(ascii_letters + digits + "_")
SECTION_SEPARATOR = ":"
STRING_DELIMITER = '"'
STRING_ESCAPE = "\\"

HEADER_COMMENT = """
Generated on {date:%Y-%m-%d %H:%M}
This is a file generated by """+PurePath(__file__).name+""" from string catalog files.
It contain message string constant definition, with a predictable name.
Sources are:
{sources}
"""

STRING_TYPE = "const char {name}[]"
TAB = " "*4


class TokenType(Enum):
    IDENTIFIER = auto()
    SECTION_SEPARATOR = auto()
    MESSAGE_STRING = auto()


@dataclass(frozen=True)
class Token:
    type: TokenType
    value: str

    def __str__(self) -> str:
        if self.type == TokenType.IDENTIFIER:
            return self.value
        elif self.type == TokenType.SECTION_SEPARATOR:
            return SECTION_SEPARATOR
        elif self.type == TokenType.MESSAGE_STRING:
            return '"' + self.value + '"'


class TokenizeError(Exception):
    pass


def tokenize(cat_file: TextIO):
    """Tokenize a cat file.
    Written fast and really badly, it will be substituted for our tokenizer after"""

    reading_token: TokenType = None
    token_content: str = None

    while True:
        ch = cat_file.read(1)
        if not ch:
            break
        if reading_token == TokenType.IDENTIFIER:
            if ch in IDENTIFIER_CHARS:
                token_content += ch
                continue  # ch is processed
            else:
                yield Token(TokenType.IDENTIFIER, token_content)
                reading_token = None
                token_content = ""

        if reading_token == TokenType.MESSAGE_STRING:
            if ch == STRING_ESCAPE:
                ch2 = cat_file.read(1)
                if not ch2:
                    break
                if ch2 == "\n":
                    continue  # escaped newline
                token_content += STRING_ESCAPE + ch2  # not checked for end of string
            elif ch == STRING_DELIMITER:
                yield Token(TokenType.MESSAGE_STRING, token_content)
                reading_token = None
                token_content = ""
            else:
                token_content += ch

            continue  # anyway ch is already processed

        if reading_token is None:
            if ch in IDENTIFIER_CHARS:
                reading_token = TokenType.IDENTIFIER
                token_content = ch
            elif ch == STRING_DELIMITER:
                reading_token = TokenType.MESSAGE_STRING
                token_content = ""
            elif ch == SECTION_SEPARATOR:
                yield Token(TokenType.SECTION_SEPARATOR, None)
            elif ch in whitespace:
                pass  # ignore
            else:
                raise TokenizeError(f"Bad char {ch}")

            continue  # anyway ch is processed

    # managing last token

    if reading_token == TokenType.IDENTIFIER:
        yield Token(TokenType.IDENTIFIER, token_content)
    elif reading_token == TokenType.MESSAGE_STRING:
        raise TokenizeError("Unexpected EOF while scanning string literal")
    else:
        pass  # EOF on no particular token


class CatalogSyntaxError(Exception):
    pass


class SectionCollideError(Exception):
    pass


def read_catalog(cat_file: TextIO, catalog: Dict[str, Dict[str, str]] = None) -> Dict[str, Dict[str, str]]:
    """Parse a catalog file into a nested dict of definitions"""
    if catalog is None:
        catalog: Dict[str, Dict[str, str]] = {}

    sectionname: str = None
    messagename: str = None
    messagevalue: str = None

    last_identifier: str = None

    for token in tokenize(cat_file):
        if token.type == TokenType.IDENTIFIER:
            if messagevalue is not None:
                catalog[sectionname][messagename] = messagevalue

            if last_identifier is not None:
                raise CatalogSyntaxError(
                    f"A {repr(SECTION_SEPARATOR)} or string literal was expected, not {token}")
            last_identifier = token.value

        elif token.type == TokenType.SECTION_SEPARATOR:
            if last_identifier is None:
                raise CatalogSyntaxError(
                    f"An identifier is needed before {repr(SECTION_SEPARATOR)}")
            sectionname = last_identifier
            if sectionname not in catalog:
                catalog[sectionname] = {}
            messagename = None
            messagevalue = None
            last_identifier = None

        elif token.type == TokenType.MESSAGE_STRING:
            if last_identifier is not None:
                messagename = last_identifier
                messagevalue = ""
                last_identifier = None
            if messagename == None:
                raise CatalogSyntaxError(
                    f"Expected an identifier before string literal {token}")
            if sectionname == None:
                raise CatalogSyntaxError(
                    f"String literal {messagename} {token} is outside all sections")
            messagevalue += token.value

    if messagevalue is not None:
        catalog[sectionname][messagename] = messagevalue

    return catalog


def write_catalog_header(
    catalog: Dict[str, Dict[str, str]],
    cat_header: TextIO,
    guards_name: str = None,
    string_prefix: str = "",
    origin_files: List[str] = None
) -> None:
    """Convert a catalog file to a catalog header 
    that can be included into a program"""

    # header comment
    print("/*" + HEADER_COMMENT.format(
        date=datetime.now(),
        sources=(TAB + f"\n{TAB}".join(origin_files)
                 ) if origin_files is not None else f"{TAB}<none>"
    ) + "*/", file=cat_header)

    print(file=cat_header)

    # opening guards
    if guards_name is not None:
        print(f"#ifndef {guards_name}", file=cat_header)
        print(f"#define {guards_name}", file=cat_header)

        print(file=cat_header)

    # dependency
    if origin_files is not None and origin_files:
        print("// keeping track of source files", file=cat_header)
        print("#ifdef __GNUC__", file=cat_header)
        for file in origin_files:
            print(
                f"#pragma GCC dependency \"{file}\" Modified file \"{file}\", catalog header need to be regenerated", file=cat_header)
        print("#endif // __GNUC__", file=cat_header)
        print(file=cat_header)

    for sectionname, sectioncontent in catalog.items():
        print(f"// {sectionname} ", file=cat_header)
        for messagename, messagecontent in sectioncontent.items():
            print((STRING_TYPE + " = \"{value}\";").format(
                name=(string_prefix + "_" if string_prefix else "") +
                f"{sectionname}_{messagename}",
                value=str(messagecontent)
            ), file=cat_header)
        print(file=cat_header)

    if guards_name is not None:
        print(file=cat_header)

        # closing guards
        print(f"#endif // {guards_name}", file=cat_header)


def get_argparser():
    """Prepare a argument parser for cli invocation"""
    parser = ArgumentParser(description=__doc__)

    parser.add_argument("inputfiles", nargs='*', type=FileType("r"), default=[
                        stdin], help="The input catalog files. If none specified read from <stdin>")
    parser.add_argument("-o", "--out", dest="outputfile", type=FileType("w"), default=None,
                        help="The output finished header. If absent defaults to <stdout>")
    parser.add_argument("-p", "--prefix", type=str, default="",
                        help="If present its uppercase version will be prefixed to every string name")

    guard_group = parser.add_mutually_exclusive_group()
    guard_group.add_argument("--no-guards", action="store_true",
                             default=False, help="If present no include guards are generated")
    guard_group.add_argument("-g", "--guards", type=str, default=None, dest="guards",
                             help="What macro is used for the include guards (defaults to sanitized and uppercased output file name, or no guard for <stdout>)")

    return parser


def sanitize(filename: str) -> str:
    return "".join(ch for ch in PurePath(filename).name.upper().replace(".", "_") if ch in IDENTIFIER_CHARS)


def main(argv: List[str]):
    # parsing arguments
    parsed_args = get_argparser().parse_args(argv[1:])

    # setting up guards
    if not parsed_args.no_guards and parsed_args.guards is None:
        # we have to decide what guard to use
        if parsed_args.outputfile is not None:
            parsed_args.guards = "_" + sanitize(parsed_args.outputfile.name)
        else:
            pass  # printing to stdout, do not put guards

    # setting print to stdout
    if parsed_args.outputfile is None:
        parsed_args.outputfile = stdout

    # parsing files
    catalog = {}
    for inp_file in parsed_args.inputfiles:
        read_catalog(inp_file, catalog)

    # writing out complete header
    write_catalog_header(
        catalog,
        parsed_args.outputfile,
        parsed_args.guards,
        parsed_args.prefix,
        [inp_file.name for inp_file in parsed_args.inputfiles]
    )


if __name__ == "__main__":
    from sys import argv
    main(argv)
